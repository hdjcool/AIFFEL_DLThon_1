{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import TFBertForSequenceClassification, TFElectraForSequenceClassification, AutoTokenizer, ElectraTokenizer\n",
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "FHcqCRSMzfa7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "klue_bert_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140\"\n",
        "koelectra_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210\""
      ],
      "metadata": {
        "id": "owf_eoMkzrKj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_FILE_PATH = \"/content/drive/MyDrive/modu/\bDLTON/aiffel-dl-thon-online-10/test_cleansed_241208.csv\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412091730.csv\"\n",
        "OUTPUT_CSV_FILE =\"/content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412091730.csv\"\n",
        "MAX_LENGTH = 489  # 토큰화된 입력의 최대 길이"
      ],
      "metadata": {
        "id": "ggMT6mGq2eR1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 매핑 정의\n",
        "class_mapping = {\n",
        "    \"협박 대화\": 0,\n",
        "    \"갈취 대화\": 1,\n",
        "    \"직장 내 괴롭힘 대화\": 2,\n",
        "    \"기타 괴롭힘 대화\": 3,\n",
        "    \"일반 대화\": 4\n",
        "}\n",
        "\n",
        "# class_mapping에서 클래스 이름 리스트 생성\n",
        "class_labels = [k for k, v in sorted(class_mapping.items(), key=lambda item: item[1])]\n",
        "\n",
        "# 클래스 수 계산\n",
        "num_classes = len(class_mapping)\n",
        "\n",
        "print(\"Class Labels:\", class_labels)\n",
        "print(\"Number of Classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWVoaYW62bG7",
        "outputId": "7596b031-7b1b-4fda-d466-62e4bd738a60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Labels: ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\n",
            "Number of Classes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저 로드 함수\n",
        "def load_kluebert_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KLUE-BERT 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KLUE-BERT 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFBertForSequenceClassification 모델\n",
        "    - tokenizer: AutoTokenizer\n",
        "    \"\"\"\n",
        "    model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "_tXILsnezh0p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_koelectra_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KoELECTRA 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KoELECTRA 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFElectraForSequenceClassification 모델\n",
        "    - tokenizer: ElectraTokenizer\n",
        "    \"\"\"\n",
        "    model = TFElectraForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = ElectraTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "uBgLNOFjzkEj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax 확률 조정 함수 (추가) # 수정된 부분\n",
        "def redistribute_softmax_predictions(probabilities, target_count, class_labels):\n",
        "    \"\"\"\n",
        "    Softmax 확률을 기반으로 클래스별 목표 개수에 맞게 예측을 재분배합니다.\n",
        "    Args:\n",
        "    - probabilities (np.ndarray): Softmax 확률 (샘플 수 x 클래스 수).\n",
        "    - target_count (int): 각 클래스별 목표 개수.\n",
        "    - class_labels (list): 클래스 이름 리스트.\n",
        "    Returns:\n",
        "    - redistributed_preds (list): 재분배된 최종 클래스 예측.\n",
        "    \"\"\"\n",
        "    num_samples = probabilities.shape[0]\n",
        "    class_counts = {label: 0 for label in class_labels}\n",
        "    redistributed_preds = [-1] * num_samples\n",
        "\n",
        "    # 각 샘플별로 높은 확률 순서대로 정렬\n",
        "    sorted_indices = np.argsort(-probabilities, axis=1)\n",
        "\n",
        "    # 목표 개수에 맞춰 재분배\n",
        "    for idx in range(num_samples):\n",
        "        for class_idx in sorted_indices[idx]:\n",
        "            class_name = class_labels[class_idx]\n",
        "            if class_counts[class_name] < target_count:\n",
        "                redistributed_preds[idx] = class_idx\n",
        "                class_counts[class_name] += 1\n",
        "                break\n",
        "\n",
        "    print(\"Redistributed Class Counts:\", Counter([class_labels[pred] for pred in redistributed_preds]))\n",
        "    return redistributed_preds"
      ],
      "metadata": {
        "id": "h7Fl88t6iF-v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Soft Voting 앙상블 함수\n",
        "def soft_voting_ensemble(models, tokenizers, texts, max_length=128, target_count=100):  # 수정된 부분: target_count 추가\n",
        "    \"\"\"\n",
        "    Soft Voting을 이용해 여러 모델의 예측을 결합하고, 클래스별 목표 개수로 재분배합니다.\n",
        "    Args:\n",
        "    - models (list): 학습된 TensorFlow 모델 리스트.\n",
        "    - tokenizers (list): 각 모델에 대응하는 Hugging Face 토크나이저 리스트.\n",
        "    - texts (list): 예측할 텍스트 리스트.\n",
        "    - max_length (int): 토큰화된 입력의 최대 길이.\n",
        "    - target_count (int): 클래스별 목표 개수.\n",
        "    Returns:\n",
        "    - final_predictions (list): 재분배된 최종 예측 클래스 인덱스.\n",
        "    - final_labels (list): 재분배된 최종 예측 클래스 이름.\n",
        "    \"\"\"\n",
        "    probabilities = []\n",
        "    for model, tokenizer in zip(models, tokenizers):\n",
        "        inputs = tokenizer(\n",
        "            texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "        preds = model.predict(dict(inputs)).logits\n",
        "        probabilities.append(tf.nn.softmax(preds, axis=1).numpy())\n",
        "\n",
        "    avg_probabilities = np.mean(probabilities, axis=0)\n",
        "\n",
        "    # Softmax 확률 조정 (추가) # 수정된 부분\n",
        "    final_predictions = redistribute_softmax_predictions(avg_probabilities, target_count, class_labels)\n",
        "    final_labels = [class_labels[pred] for pred in final_predictions]\n",
        "\n",
        "    return final_predictions, final_labels"
      ],
      "metadata": {
        "id": "EzR26VoTznx5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction 결과 저장 함수\n",
        "def predict_and_save_files(models, tokenizers, test_data, predictions_file, submission_file, max_length=128, target_count=100):  # 수정된 부분: target_count 추가\n",
        "    \"\"\"\n",
        "    Soft Voting을 사용해 테스트 데이터를 예측하고, 예측 결과를 포함한 두 개의 파일을 저장합니다.\n",
        "    \"\"\"\n",
        "    texts = test_data['text'].tolist()\n",
        "\n",
        "    # Soft Voting 앙상블 예측\n",
        "    predicted_classes, predicted_labels = soft_voting_ensemble(models, tokenizers, texts, max_length, target_count)  # 수정된 부분: target_count 전달\n",
        "\n",
        "    # 예측 결과를 데이터프레임에 추가\n",
        "    test_data['predicted_class_index'] = predicted_classes\n",
        "    test_data['predicted_class_name'] = predicted_labels\n",
        "\n",
        "    # 클래스별 예측 개수 출력\n",
        "    class_counts = Counter(predicted_labels)\n",
        "    print(\"\\nClass Prediction Counts:\")\n",
        "    for class_name, count in class_counts.items():\n",
        "        print(f\"{class_name}: {count}\")\n",
        "\n",
        "    # train_dataset_with_predictions.csv 저장\n",
        "    test_data.to_csv(predictions_file, index=False)\n",
        "    print(f\"\\nPredictions saved to {predictions_file}\")\n",
        "\n",
        "    # submission.csv 저장\n",
        "    submission = pd.DataFrame({\n",
        "        \"idx\": test_data['idx'],\n",
        "        \"target\": predicted_classes\n",
        "    })\n",
        "    submission.to_csv(submission_file, index=False)\n",
        "    print(f\"Submission file saved to {submission_file}\")"
      ],
      "metadata": {
        "id": "obUxrZUT8g-a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 및 토크나이저 로드\n",
        "klue_bert_model, klue_bert_tokenizer = load_kluebert_model_and_tokenizer(klue_bert_path)\n",
        "koelectra_model, koelectra_tokenizer = load_koelectra_model_and_tokenizer(koelectra_path)\n",
        "\n",
        "# 모델과 토크나이저 리스트\n",
        "models = [klue_bert_model, koelectra_model]\n",
        "tokenizers = [klue_bert_tokenizer, koelectra_tokenizer]"
      ],
      "metadata": {
        "id": "ijwjbrdhzxXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1459b27f-9fd3-40fa-8351-779eee43b1e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFElectraForSequenceClassification.\n",
            "\n",
            "All the layers of TFElectraForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TzlOi_wGzCK8"
      },
      "outputs": [],
      "source": [
        "# # 테스트 데이터\n",
        "# texts = [\n",
        "#     \"이 문장은 테스트 문장입니다.\",\n",
        "#     \"예제 문장이며 결과를 확인해 봅니다.\",\n",
        "#     \"어떤 클래스에 속할지 궁금합니다.\"\n",
        "# ]\n",
        "\n",
        "# # Soft Voting 앙상블 예측\n",
        "# ensemble_predictions = soft_voting_ensemble(models, tokenizers, texts)\n",
        "\n",
        "# # 결과 출력\n",
        "# print(\"Soft Voting Predictions:\", ensemble_predictions)\n",
        "\n",
        "# # 클래스 이름 매핑 (필요 시)\n",
        "# class_labels = [\"협박 대화\", \"갈취 대화\", \"직장 내 괴롭힘 대화\", \"기타 괴롭힘 대화\", \"일반 대화\"]\n",
        "# print(\"Predicted Classes:\", [class_labels[pred] for pred in ensemble_predictions])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "test_data = pd.read_csv(TEST_FILE_PATH)\n",
        "\n",
        "# 예측 및 저장\n",
        "predict_and_save_files(\n",
        "    models=models,\n",
        "    tokenizers=tokenizers,\n",
        "    test_data=test_data,\n",
        "    predictions_file=OUTPUT_CSV_FILE,\n",
        "    submission_file=OUTPUT_FILE,\n",
        "    max_length=128,\n",
        "    target_count=100  # 수정된 부분\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t79LS9cG1tje",
        "outputId": "c8fa8ffe-9c7a-4e9f-c1d8-cb952145c184"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 297s 17s/step\n",
            "16/16 [==============================] - 260s 16s/step\n",
            "Redistributed Class Counts: Counter({'갈취 대화': 100, '직장 내 괴롭힘 대화': 100, '일반 대화': 100, '기타 괴롭힘 대화': 100, '협박 대화': 100})\n",
            "\n",
            "Class Prediction Counts:\n",
            "갈취 대화: 100\n",
            "직장 내 괴롭힘 대화: 100\n",
            "일반 대화: 100\n",
            "기타 괴롭힘 대화: 100\n",
            "협박 대화: 100\n",
            "\n",
            "Predictions saved to /content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412091730.csv\n",
            "Submission file saved to /content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412091730.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 수정된 부분 요약\n",
        "1. redistribute_softmax_predictions 함수 추가:\n",
        "    - 클래스별 목표 개수를 맞추기 위해 Softmax 확률을 조정하는 로직.\n",
        "2. soft_voting_ensemble 함수 수정:\n",
        "    - Softmax 확률 조정을 호출하여 재분배된 결과를 반환.\n",
        "3. predict_and_save_files 함수 수정:\n",
        "    - target_count 매개변수를 추가하여 목표 개수를 전달.\n",
        "4. target_count=100 기본값 설정:\n",
        "    - 클래스별 100개를 목표로 설정."
      ],
      "metadata": {
        "id": "eg3EkNFLjPEZ"
      }
    }
  ]
}