{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import TFBertForSequenceClassification, TFElectraForSequenceClassification, AutoTokenizer, ElectraTokenizer\n",
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "FHcqCRSMzfa7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "klue_bert_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140\"\n",
        "koelectra_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210\""
      ],
      "metadata": {
        "id": "owf_eoMkzrKj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_FILE_PATH = \"/content/drive/MyDrive/modu/\bDLTON/aiffel-dl-thon-online-10/test_cleansed_241208.csv\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412091750.csv\"\n",
        "OUTPUT_CSV_FILE =\"/content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412091750.csv\"\n",
        "MAX_LENGTH = 489  # 토큰화된 입력의 최대 길이"
      ],
      "metadata": {
        "id": "ggMT6mGq2eR1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 매핑 정의\n",
        "class_mapping = {\n",
        "    \"협박 대화\": 0,\n",
        "    \"갈취 대화\": 1,\n",
        "    \"직장 내 괴롭힘 대화\": 2,\n",
        "    \"기타 괴롭힘 대화\": 3,\n",
        "    \"일반 대화\": 4\n",
        "}\n",
        "\n",
        "# class_mapping에서 클래스 이름 리스트 생성\n",
        "class_labels = [k for k, v in sorted(class_mapping.items(), key=lambda item: item[1])]\n",
        "\n",
        "# 클래스 수 계산\n",
        "num_classes = len(class_mapping)\n",
        "\n",
        "print(\"Class Labels:\", class_labels)\n",
        "print(\"Number of Classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWVoaYW62bG7",
        "outputId": "3ab78af8-ab54-416b-c551-bca1cba3860a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Labels: ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\n",
            "Number of Classes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저 로드 함수\n",
        "def load_kluebert_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KLUE-BERT 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KLUE-BERT 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFBertForSequenceClassification 모델\n",
        "    - tokenizer: AutoTokenizer\n",
        "    \"\"\"\n",
        "    model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "_tXILsnezh0p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_koelectra_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KoELECTRA 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KoELECTRA 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFElectraForSequenceClassification 모델\n",
        "    - tokenizer: ElectraTokenizer\n",
        "    \"\"\"\n",
        "    model = TFElectraForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = ElectraTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "uBgLNOFjzkEj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Soft Voting 앙상블 함수\n",
        "def soft_voting_ensemble(models, tokenizers, texts, max_length=128):\n",
        "    \"\"\"\n",
        "    Soft Voting을 이용해 여러 모델의 예측을 결합하여 최종 클래스를 예측합니다.\n",
        "    Args:\n",
        "    - models (list): 학습된 TensorFlow 모델 리스트.\n",
        "    - tokenizers (list): 각 모델에 대응하는 Hugging Face 토크나이저 리스트.\n",
        "    - texts (list): 예측할 텍스트 리스트.\n",
        "    - max_length (int): 토큰화된 입력의 최대 길이.\n",
        "\n",
        "    Returns:\n",
        "    - final_predictions (list): Soft Voting으로 앙상블된 최종 예측 클래스 인덱스.\n",
        "    - final_labels (list): Soft Voting으로 앙상블된 최종 예측 클래스 이름.\n",
        "    \"\"\"\n",
        "    probabilities = []\n",
        "    for model, tokenizer in zip(models, tokenizers):\n",
        "        inputs = tokenizer(\n",
        "            texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "        preds = model.predict(dict(inputs)).logits\n",
        "        probabilities.append(tf.nn.softmax(preds, axis=1).numpy())\n",
        "\n",
        "    avg_probabilities = np.mean(probabilities, axis=0)\n",
        "    final_predictions = np.argmax(avg_probabilities, axis=1)\n",
        "    final_labels = [class_labels[pred] for pred in final_predictions]\n",
        "\n",
        "    return final_predictions, final_labels"
      ],
      "metadata": {
        "id": "EzR26VoTznx5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction 결과 저장 함수\n",
        "def predict_and_save_files(models, tokenizers, test_data, predictions_file, submission_file, max_length=128):\n",
        "    \"\"\"\n",
        "    Soft Voting을 사용해 테스트 데이터를 예측하고, 예측 결과를 포함한 두 개의 파일을 저장합니다.\n",
        "    Args:\n",
        "    - models: 학습된 모델 리스트\n",
        "    - tokenizers: Hugging Face 토크나이저 리스트\n",
        "    - test_data: pandas DataFrame (idx, conversation 열 포함)\n",
        "    - predictions_file (str): train_dataset_with_predictions.csv 저장 경로\n",
        "    - submission_file (str): submission.csv 저장 경로\n",
        "    - max_length (int): 토큰화된 입력의 최대 길이\n",
        "    \"\"\"\n",
        "    texts = test_data['text'].tolist()\n",
        "\n",
        "    # Soft Voting 앙상블 예측\n",
        "    predicted_classes, predicted_labels = soft_voting_ensemble(models, tokenizers, texts, max_length)\n",
        "\n",
        "    # 예측 결과를 데이터프레임에 추가\n",
        "    test_data['predicted_class_index'] = predicted_classes\n",
        "    test_data['predicted_class_name'] = predicted_labels\n",
        "\n",
        "    # 클래스별 예측 개수 출력\n",
        "    class_counts = Counter(predicted_labels)\n",
        "    print(\"\\nClass Prediction Counts:\")\n",
        "    for class_name, count in class_counts.items():\n",
        "        print(f\"{class_name}: {count}\")\n",
        "\n",
        "    # train_dataset_with_predictions.csv 저장\n",
        "    test_data.to_csv(predictions_file, index=False)\n",
        "    print(f\"\\nPredictions saved to {predictions_file}\")\n",
        "\n",
        "    # submission.csv 저장\n",
        "    submission = pd.DataFrame({\n",
        "        \"idx\": test_data['idx'],      # 파일 이름 또는 고유 식별자\n",
        "        \"target\": predicted_classes   # 정수형 클래스 ID\n",
        "    })\n",
        "    submission.to_csv(submission_file, index=False)\n",
        "    print(f\"Submission file saved to {submission_file}\")"
      ],
      "metadata": {
        "id": "obUxrZUT8g-a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 및 토크나이저 로드\n",
        "klue_bert_model, klue_bert_tokenizer = load_kluebert_model_and_tokenizer(klue_bert_path)\n",
        "koelectra_model, koelectra_tokenizer = load_koelectra_model_and_tokenizer(koelectra_path)\n",
        "\n",
        "# 모델과 토크나이저 리스트\n",
        "models = [klue_bert_model, koelectra_model]\n",
        "tokenizers = [klue_bert_tokenizer, koelectra_tokenizer]"
      ],
      "metadata": {
        "id": "ijwjbrdhzxXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e45039a-81f0-4f37-e182-14525c986f4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFElectraForSequenceClassification.\n",
            "\n",
            "All the layers of TFElectraForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TzlOi_wGzCK8"
      },
      "outputs": [],
      "source": [
        "# # 테스트 데이터\n",
        "# texts = [\n",
        "#     \"이 문장은 테스트 문장입니다.\",\n",
        "#     \"예제 문장이며 결과를 확인해 봅니다.\",\n",
        "#     \"어떤 클래스에 속할지 궁금합니다.\"\n",
        "# ]\n",
        "\n",
        "# # Soft Voting 앙상블 예측\n",
        "# ensemble_predictions = soft_voting_ensemble(models, tokenizers, texts)\n",
        "\n",
        "# # 결과 출력\n",
        "# print(\"Soft Voting Predictions:\", ensemble_predictions)\n",
        "\n",
        "# # 클래스 이름 매핑 (필요 시)\n",
        "# class_labels = [\"협박 대화\", \"갈취 대화\", \"직장 내 괴롭힘 대화\", \"기타 괴롭힘 대화\", \"일반 대화\"]\n",
        "# print(\"Predicted Classes:\", [class_labels[pred] for pred in ensemble_predictions])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "test_data = pd.read_csv(TEST_FILE_PATH)\n",
        "\n",
        "# 예측 및 저장\n",
        "predict_and_save_files(\n",
        "    models=models,\n",
        "    tokenizers=tokenizers,\n",
        "    test_data=test_data,\n",
        "    predictions_file=OUTPUT_CSV_FILE,\n",
        "    submission_file=OUTPUT_FILE,\n",
        "    max_length=128\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t79LS9cG1tje",
        "outputId": "54888504-134b-4177-e157-eed2c3a9723a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 258s 16s/step\n",
            "16/16 [==============================] - 259s 16s/step\n",
            "\n",
            "Class Prediction Counts:\n",
            "갈취 대화: 92\n",
            "직장 내 괴롭힘 대화: 98\n",
            "일반 대화: 81\n",
            "기타 괴롭힘 대화: 148\n",
            "협박 대화: 81\n",
            "\n",
            "Predictions saved to /content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412091750.csv\n",
            "Submission file saved to /content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412091750.csv\n"
          ]
        }
      ]
    }
  ]
}