{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import TFBertForSequenceClassification, TFElectraForSequenceClassification, AutoTokenizer, ElectraTokenizer\n",
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "FHcqCRSMzfa7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "klue_bert_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140\"\n",
        "koelectra_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210\""
      ],
      "metadata": {
        "id": "owf_eoMkzrKj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_FILE_PATH = \"/content/drive/MyDrive/modu/\bDLTON/aiffel-dl-thon-online-10/test_cleansed_241208.csv\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412092110.csv\"\n",
        "OUTPUT_CSV_FILE =\"/content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412092110.csv\"\n",
        "MAX_LENGTH = 489  # 토큰화된 입력의 최대 길이"
      ],
      "metadata": {
        "id": "ggMT6mGq2eR1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 매핑 정의\n",
        "class_mapping = {\n",
        "    \"협박 대화\": 0,\n",
        "    \"갈취 대화\": 1,\n",
        "    \"직장 내 괴롭힘 대화\": 2,\n",
        "    \"기타 괴롭힘 대화\": 3,\n",
        "    \"일반 대화\": 4\n",
        "}\n",
        "\n",
        "# class_mapping에서 클래스 이름 리스트 생성\n",
        "class_labels = [k for k, v in sorted(class_mapping.items(), key=lambda item: item[1])]\n",
        "\n",
        "# 클래스 수 계산\n",
        "num_classes = len(class_mapping)\n",
        "\n",
        "print(\"Class Labels:\", class_labels)\n",
        "print(\"Number of Classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWVoaYW62bG7",
        "outputId": "dbc4a2ee-00cf-42c7-f047-20554a8831e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Labels: ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\n",
            "Number of Classes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저 로드 함수\n",
        "def load_kluebert_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KLUE-BERT 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KLUE-BERT 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFBertForSequenceClassification 모델\n",
        "    - tokenizer: AutoTokenizer\n",
        "    \"\"\"\n",
        "    model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "_tXILsnezh0p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_koelectra_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KoELECTRA 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KoELECTRA 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFElectraForSequenceClassification 모델\n",
        "    - tokenizer: ElectraTokenizer\n",
        "    \"\"\"\n",
        "    model = TFElectraForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = ElectraTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "uBgLNOFjzkEj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax 확률 조정을 위한 Weighted Sampling 함수 (추가) # 수정된 부분\n",
        "def apply_weighted_sampling(probabilities, class_weights):\n",
        "    \"\"\"\n",
        "    클래스별 가중치를 적용하여 Softmax 확률을 조정합니다.\n",
        "    Args:\n",
        "    - probabilities (np.ndarray): Softmax 확률 (샘플 수 x 클래스 수).\n",
        "    - class_weights (dict): 클래스별 가중치 딕셔너리.\n",
        "    Returns:\n",
        "    - adjusted_probabilities (np.ndarray): 조정된 Softmax 확률.\n",
        "    \"\"\"\n",
        "    # 각 클래스별 가중치를 적용\n",
        "    adjusted_probabilities = probabilities * np.array([class_weights[i] for i in range(len(class_weights))])\n",
        "    # 확률 정규화 (각 샘플의 확률 합이 1이 되도록)\n",
        "    adjusted_probabilities /= adjusted_probabilities.sum(axis=1, keepdims=True)\n",
        "    return adjusted_probabilities"
      ],
      "metadata": {
        "id": "h7Fl88t6iF-v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Soft Voting 앙상블 함수 수정 (Weighted Sampling 적용) # 수정된 부분\n",
        "def soft_voting_ensemble_with_weighted_sampling(models, tokenizers, texts, class_weights, max_length=128):\n",
        "    \"\"\"\n",
        "    Weighted Sampling을 적용한 Soft Voting 앙상블.\n",
        "    Args:\n",
        "    - models (list): 학습된 TensorFlow 모델 리스트.\n",
        "    - tokenizers (list): 각 모델에 대응하는 Hugging Face 토크나이저 리스트.\n",
        "    - texts (list): 예측할 텍스트 리스트.\n",
        "    - class_weights (dict): 클래스별 가중치 딕셔너리.\n",
        "    - max_length (int): 토큰화된 입력의 최대 길이.\n",
        "    Returns:\n",
        "    - final_predictions (list): Weighted Sampling 적용 후 Soft Voting으로 앙상블된 최종 클래스 인덱스.\n",
        "    - final_labels (list): Soft Voting으로 앙상블된 최종 클래스 이름.\n",
        "    \"\"\"\n",
        "    probabilities = []\n",
        "    for model, tokenizer in zip(models, tokenizers):\n",
        "        # 입력 텍스트를 토크나이징\n",
        "        inputs = tokenizer(\n",
        "            texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "\n",
        "        # 모델 예측 (Logits 출력)\n",
        "        logits = model.predict(dict(inputs)).logits\n",
        "\n",
        "        # Softmax 확률 계산\n",
        "        softmax_probabilities = tf.nn.softmax(logits, axis=1).numpy()\n",
        "\n",
        "        # Weighted Sampling 적용 (수정된 부분)\n",
        "        weighted_probabilities = apply_weighted_sampling(softmax_probabilities, class_weights)\n",
        "\n",
        "        probabilities.append(weighted_probabilities)\n",
        "\n",
        "    # Soft Voting: 모든 모델의 확률 평균 계산\n",
        "    avg_probabilities = np.mean(probabilities, axis=0)\n",
        "    final_predictions = np.argmax(avg_probabilities, axis=1)\n",
        "    final_labels = [class_labels[pred] for pred in final_predictions]\n",
        "\n",
        "    return final_predictions, final_labels"
      ],
      "metadata": {
        "id": "EzR26VoTznx5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction 결과 저장 함수 수정 (Weighted Sampling 추가) # 수정된 부분\n",
        "def predict_and_save_files_with_weighted_sampling(\n",
        "    models, tokenizers, test_data, predictions_file, submission_file, class_weights, max_length=128):\n",
        "    \"\"\"\n",
        "    Weighted Sampling을 적용한 Soft Voting을 사용해 테스트 데이터를 예측하고, 예측 결과를 저장합니다.\n",
        "    Args:\n",
        "    - models (list): 학습된 모델 리스트\n",
        "    - tokenizers (list): Hugging Face 토크나이저 리스트\n",
        "    - test_data: pandas DataFrame (idx, text 열 포함)\n",
        "    - predictions_file (str): train_dataset_with_predictions.csv 저장 경로\n",
        "    - submission_file (str): submission.csv 저장 경로\n",
        "    - class_weights (dict): 클래스별 가중치 딕셔너리.\n",
        "    - max_length (int): 토큰화된 입력의 최대 길이.\n",
        "    \"\"\"\n",
        "    texts = test_data['text'].tolist()\n",
        "\n",
        "    # Soft Voting 앙상블 예측\n",
        "    predicted_classes, predicted_labels = soft_voting_ensemble_with_weighted_sampling(\n",
        "        models=models,\n",
        "        tokenizers=tokenizers,\n",
        "        texts=texts,\n",
        "        class_weights=class_weights,  # 수정된 부분: 클래스 가중치 전달\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "    # 예측 결과를 데이터프레임에 추가\n",
        "    test_data['predicted_class_index'] = predicted_classes\n",
        "    test_data['predicted_class_name'] = predicted_labels\n",
        "\n",
        "    # 클래스별 예측 개수 출력\n",
        "    class_counts = Counter(predicted_labels)\n",
        "    print(\"\\nClass Prediction Counts:\")\n",
        "    for class_name, count in class_counts.items():\n",
        "        print(f\"{class_name}: {count}\")\n",
        "\n",
        "    # train_dataset_with_predictions.csv 저장\n",
        "    test_data.to_csv(predictions_file, index=False)\n",
        "    print(f\"\\nPredictions saved to {predictions_file}\")\n",
        "\n",
        "    # submission.csv 저장\n",
        "    submission = pd.DataFrame({\n",
        "        \"idx\": test_data['idx'],  # 파일 이름 또는 고유 식별자\n",
        "        \"target\": predicted_classes  # 정수형 클래스 ID\n",
        "    })\n",
        "    submission.to_csv(submission_file, index=False)\n",
        "    print(f\"Submission file saved to {submission_file}\")"
      ],
      "metadata": {
        "id": "obUxrZUT8g-a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 및 토크나이저 로드\n",
        "klue_bert_model, klue_bert_tokenizer = load_kluebert_model_and_tokenizer(klue_bert_path)\n",
        "koelectra_model, koelectra_tokenizer = load_koelectra_model_and_tokenizer(koelectra_path)\n",
        "\n",
        "# 모델과 토크나이저 리스트\n",
        "models = [klue_bert_model, koelectra_model]\n",
        "tokenizers = [klue_bert_tokenizer, koelectra_tokenizer]"
      ],
      "metadata": {
        "id": "ijwjbrdhzxXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c8958e-8e52-4111-e9ae-cef46d6da755"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFElectraForSequenceClassification.\n",
            "\n",
            "All the layers of TFElectraForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TzlOi_wGzCK8"
      },
      "outputs": [],
      "source": [
        "# # 테스트 데이터\n",
        "# texts = [\n",
        "#     \"이 문장은 테스트 문장입니다.\",\n",
        "#     \"예제 문장이며 결과를 확인해 봅니다.\",\n",
        "#     \"어떤 클래스에 속할지 궁금합니다.\"\n",
        "# ]\n",
        "\n",
        "# # Soft Voting 앙상블 예측\n",
        "# ensemble_predictions = soft_voting_ensemble(models, tokenizers, texts)\n",
        "\n",
        "# # 결과 출력\n",
        "# print(\"Soft Voting Predictions:\", ensemble_predictions)\n",
        "\n",
        "# # 클래스 이름 매핑 (필요 시)\n",
        "# class_labels = [\"협박 대화\", \"갈취 대화\", \"직장 내 괴롭힘 대화\", \"기타 괴롭힘 대화\", \"일반 대화\"]\n",
        "# print(\"Predicted Classes:\", [class_labels[pred] for pred in ensemble_predictions])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_weights(current_counts, target_count):\n",
        "    \"\"\"\n",
        "    현재 클래스 개수와 목표 개수를 기반으로 클래스 가중치를 계산합니다.\n",
        "    Args:\n",
        "    - current_counts (dict): 현재 클래스별 개수 (예: {'협박 대화': 76, ...}).\n",
        "    - target_count (int): 모든 클래스의 목표 개수.\n",
        "    Returns:\n",
        "    - class_weights (dict): 클래스별 가중치 딕셔너리.\n",
        "    \"\"\"\n",
        "    class_weights = {}\n",
        "    for class_label, count in current_counts.items():\n",
        "        class_weights[class_label] = target_count / count\n",
        "    return class_weights"
      ],
      "metadata": {
        "id": "oq9WYnsuHcqf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 클래스 예측 분포\n",
        "current_counts = {\n",
        "    \"협박 대화\": 92,\n",
        "    \"갈취 대화\": 98,\n",
        "    \"직장 내 괴롭힘 대화\": 81,\n",
        "    \"기타 괴롭힘 대화\": 148,\n",
        "    \"일반 대화\": 81\n",
        "}\n",
        "\n",
        "# 목표 개수 설정\n",
        "target_count = 100\n",
        "\n",
        "# 가중치 계산\n",
        "class_weights = calculate_class_weights(current_counts, target_count)\n",
        "\n",
        "# 클래스 이름 대신 클래스 ID로 변환\n",
        "class_weights_numeric = {class_mapping[label]: weight for label, weight in class_weights.items()}\n",
        "\n",
        "print(\"Class Weights:\", class_weights_numeric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NJjpHgfGw95",
        "outputId": "1c7d30c5-695c-44ef-8d12-a2e1ebf4358d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.0869565217391304, 1: 1.0204081632653061, 2: 1.2345679012345678, 3: 0.6756756756756757, 4: 1.2345679012345678}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "test_data = pd.read_csv(TEST_FILE_PATH)\n",
        "\n",
        "# 예측 및 파일 저장\n",
        "predict_and_save_files_with_weighted_sampling(\n",
        "    models=models,\n",
        "    tokenizers=tokenizers,\n",
        "    test_data=test_data,\n",
        "    predictions_file=OUTPUT_CSV_FILE,\n",
        "    submission_file=OUTPUT_FILE,\n",
        "    class_weights=class_weights_numeric,  # 수정된 부분\n",
        "    max_length=MAX_LENGTH\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t79LS9cG1tje",
        "outputId": "bf4514e5-ffd3-42c8-bdd1-9a3b66dd576d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 27s 1s/step\n",
            "16/16 [==============================] - 26s 1s/step\n",
            "\n",
            "Class Prediction Counts:\n",
            "갈취 대화: 94\n",
            "직장 내 괴롭힘 대화: 100\n",
            "일반 대화: 80\n",
            "기타 괴롭힘 대화: 130\n",
            "협박 대화: 96\n",
            "\n",
            "Predictions saved to /content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412092110.csv\n",
            "Submission file saved to /content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412092110.csv\n"
          ]
        }
      ]
    }
  ]
}