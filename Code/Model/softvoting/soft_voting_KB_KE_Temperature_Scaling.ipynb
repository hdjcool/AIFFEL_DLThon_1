{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import TFBertForSequenceClassification, TFElectraForSequenceClassification, AutoTokenizer, ElectraTokenizer\n",
        "\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "FHcqCRSMzfa7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "klue_bert_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140\"\n",
        "koelectra_path = \"/content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210\""
      ],
      "metadata": {
        "id": "owf_eoMkzrKj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_FILE_PATH = \"/content/drive/MyDrive/modu/\bDLTON/aiffel-dl-thon-online-10/test_cleansed_241208.csv\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412092105.csv\"\n",
        "OUTPUT_CSV_FILE =\"/content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412092105.csv\"\n",
        "MAX_LENGTH = 489  # 토큰화된 입력의 최대 길이"
      ],
      "metadata": {
        "id": "ggMT6mGq2eR1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 매핑 정의\n",
        "class_mapping = {\n",
        "    \"협박 대화\": 0,\n",
        "    \"갈취 대화\": 1,\n",
        "    \"직장 내 괴롭힘 대화\": 2,\n",
        "    \"기타 괴롭힘 대화\": 3,\n",
        "    \"일반 대화\": 4\n",
        "}\n",
        "\n",
        "# class_mapping에서 클래스 이름 리스트 생성\n",
        "class_labels = [k for k, v in sorted(class_mapping.items(), key=lambda item: item[1])]\n",
        "\n",
        "# 클래스 수 계산\n",
        "num_classes = len(class_mapping)\n",
        "\n",
        "print(\"Class Labels:\", class_labels)\n",
        "print(\"Number of Classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWVoaYW62bG7",
        "outputId": "336a9a25-e8d9-469e-efd1-3255ac4574ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Labels: ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\n",
            "Number of Classes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저 로드 함수\n",
        "def load_kluebert_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KLUE-BERT 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KLUE-BERT 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFBertForSequenceClassification 모델\n",
        "    - tokenizer: AutoTokenizer\n",
        "    \"\"\"\n",
        "    model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "_tXILsnezh0p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_koelectra_model_and_tokenizer(model_path):\n",
        "    \"\"\"\n",
        "    KoELECTRA 모델과 토크나이저를 로드합니다.\n",
        "    Args:\n",
        "    - model_path (str): KoELECTRA 모델 저장 경로\n",
        "    Returns:\n",
        "    - model: TFElectraForSequenceClassification 모델\n",
        "    - tokenizer: ElectraTokenizer\n",
        "    \"\"\"\n",
        "    model = TFElectraForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = ElectraTokenizer.from_pretrained(model_path)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "uBgLNOFjzkEj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax 확률 조정을 위한 Temperature Scaling 함수 (추가) # 수정된 부분\n",
        "def apply_temperature_scaling(logits, temperature=1.5):\n",
        "    \"\"\"\n",
        "    Temperature Scaling을 적용하여 Softmax 확률을 조정합니다.\n",
        "    Args:\n",
        "    - logits (np.ndarray): 모델의 Logit 출력 (샘플 수 x 클래스 수).\n",
        "    - temperature (float): Softmax를 평탄화하는 온도 매개변수.\n",
        "    Returns:\n",
        "    - probabilities (np.ndarray): 조정된 Softmax 확률.\n",
        "    \"\"\"\n",
        "    scaled_logits = logits / temperature\n",
        "    probabilities = tf.nn.softmax(scaled_logits, axis=1).numpy()\n",
        "    return probabilities"
      ],
      "metadata": {
        "id": "h7Fl88t6iF-v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Soft Voting 앙상블 함수 수정 (Temperature Scaling 적용) # 수정된 부분\n",
        "def soft_voting_ensemble_with_temperature_scaling(models, tokenizers, texts, max_length=128, temperature=1.5):\n",
        "    \"\"\"\n",
        "    Temperature Scaling을 적용한 Soft Voting 앙상블.\n",
        "    Args:\n",
        "    - models (list): 학습된 TensorFlow 모델 리스트.\n",
        "    - tokenizers (list): 각 모델에 대응하는 Hugging Face 토크나이저 리스트.\n",
        "    - texts (list): 예측할 텍스트 리스트.\n",
        "    - max_length (int): 토큰화된 입력의 최대 길이.\n",
        "    - temperature (float): Softmax Temperature Scaling 매개변수.\n",
        "    Returns:\n",
        "    - final_predictions (list): Temperature Scaling 적용 후 Soft Voting으로 앙상블된 최종 클래스 인덱스.\n",
        "    - final_labels (list): Soft Voting으로 앙상블된 최종 클래스 이름.\n",
        "    \"\"\"\n",
        "    probabilities = []\n",
        "    for model, tokenizer in zip(models, tokenizers):\n",
        "        # 입력 텍스트를 토크나이징\n",
        "        inputs = tokenizer(\n",
        "            texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "\n",
        "        # 모델 예측 (Logits 출력)\n",
        "        logits = model.predict(dict(inputs)).logits\n",
        "\n",
        "        # Temperature Scaling 적용 (수정된 부분)\n",
        "        scaled_probabilities = apply_temperature_scaling(logits, temperature)\n",
        "\n",
        "        # Softmax 확률 추가\n",
        "        probabilities.append(scaled_probabilities)\n",
        "\n",
        "    # Soft Voting: 모든 모델의 확률 평균 계산\n",
        "    avg_probabilities = np.mean(probabilities, axis=0)\n",
        "    final_predictions = np.argmax(avg_probabilities, axis=1)\n",
        "    final_labels = [class_labels[pred] for pred in final_predictions]\n",
        "\n",
        "    return final_predictions, final_labels"
      ],
      "metadata": {
        "id": "EzR26VoTznx5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction 결과 저장 함수 수정 (Temperature Scaling 추가) # 수정된 부분\n",
        "def predict_and_save_files_with_temperature_scaling(\n",
        "    models, tokenizers, test_data, predictions_file, submission_file, max_length=128, temperature=1.5):\n",
        "    \"\"\"\n",
        "    Temperature Scaling을 적용한 Soft Voting을 사용해 테스트 데이터를 예측하고, 예측 결과를 저장합니다.\n",
        "    Args:\n",
        "    - models (list): 학습된 모델 리스트\n",
        "    - tokenizers (list): Hugging Face 토크나이저 리스트\n",
        "    - test_data: pandas DataFrame (idx, text 열 포함)\n",
        "    - predictions_file (str): train_dataset_with_predictions.csv 저장 경로\n",
        "    - submission_file (str): submission.csv 저장 경로\n",
        "    - max_length (int): 토큰화된 입력의 최대 길이\n",
        "    - temperature (float): Softmax Temperature Scaling 매개변수.\n",
        "    \"\"\"\n",
        "    texts = test_data['text'].tolist()\n",
        "\n",
        "    # Soft Voting 앙상블 예측\n",
        "    predicted_classes, predicted_labels = soft_voting_ensemble_with_temperature_scaling(\n",
        "        models, tokenizers, texts, max_length, temperature  # 수정된 부분: Temperature Scaling 적용\n",
        "    )\n",
        "\n",
        "    # 예측 결과를 데이터프레임에 추가\n",
        "    test_data['predicted_class_index'] = predicted_classes\n",
        "    test_data['predicted_class_name'] = predicted_labels\n",
        "\n",
        "    # 클래스별 예측 개수 출력\n",
        "    class_counts = Counter(predicted_labels)\n",
        "    print(\"\\nClass Prediction Counts:\")\n",
        "    for class_name, count in class_counts.items():\n",
        "        print(f\"{class_name}: {count}\")\n",
        "\n",
        "    # train_dataset_with_predictions.csv 저장\n",
        "    test_data.to_csv(predictions_file, index=False)\n",
        "    print(f\"\\nPredictions saved to {predictions_file}\")\n",
        "\n",
        "    # submission.csv 저장\n",
        "    submission = pd.DataFrame({\n",
        "        \"idx\": test_data['idx'],  # 파일 이름 또는 고유 식별자\n",
        "        \"target\": predicted_classes  # 정수형 클래스 ID\n",
        "    })\n",
        "    submission.to_csv(submission_file, index=False)\n",
        "    print(f\"Submission file saved to {submission_file}\")"
      ],
      "metadata": {
        "id": "obUxrZUT8g-a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 및 토크나이저 로드\n",
        "klue_bert_model, klue_bert_tokenizer = load_kluebert_model_and_tokenizer(klue_bert_path)\n",
        "koelectra_model, koelectra_tokenizer = load_koelectra_model_and_tokenizer(koelectra_path)\n",
        "\n",
        "# 모델과 토크나이저 리스트\n",
        "models = [klue_bert_model, koelectra_model]\n",
        "tokenizers = [klue_bert_tokenizer, koelectra_tokenizer]"
      ],
      "metadata": {
        "id": "ijwjbrdhzxXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dca7819-d982-4522-8c5c-4cde2502a5c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_klue-bert_model_2412081140.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFElectraForSequenceClassification.\n",
            "\n",
            "All the layers of TFElectraForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/modu/\bDLTON/model/final_koelectra_model_2412082210.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TzlOi_wGzCK8"
      },
      "outputs": [],
      "source": [
        "# # 테스트 데이터\n",
        "# texts = [\n",
        "#     \"이 문장은 테스트 문장입니다.\",\n",
        "#     \"예제 문장이며 결과를 확인해 봅니다.\",\n",
        "#     \"어떤 클래스에 속할지 궁금합니다.\"\n",
        "# ]\n",
        "\n",
        "# # Soft Voting 앙상블 예측\n",
        "# ensemble_predictions = soft_voting_ensemble(models, tokenizers, texts)\n",
        "\n",
        "# # 결과 출력\n",
        "# print(\"Soft Voting Predictions:\", ensemble_predictions)\n",
        "\n",
        "# # 클래스 이름 매핑 (필요 시)\n",
        "# class_labels = [\"협박 대화\", \"갈취 대화\", \"직장 내 괴롭힘 대화\", \"기타 괴롭힘 대화\", \"일반 대화\"]\n",
        "# print(\"Predicted Classes:\", [class_labels[pred] for pred in ensemble_predictions])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "test_data = pd.read_csv(TEST_FILE_PATH)\n",
        "\n",
        "# 예측 및 파일 저장\n",
        "predict_and_save_files_with_temperature_scaling(\n",
        "    models=models,\n",
        "    tokenizers=tokenizers,\n",
        "    test_data=test_data,\n",
        "    predictions_file=OUTPUT_CSV_FILE,\n",
        "    submission_file=OUTPUT_FILE,\n",
        "    max_length=MAX_LENGTH,\n",
        "    temperature=1.5  # 수정된 부분: Temperature Scaling 매개변수 전달\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t79LS9cG1tje",
        "outputId": "74eb0a28-8fd3-471e-aea7-2fb42f4d93a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 27s 1s/step\n",
            "16/16 [==============================] - 23s 1s/step\n",
            "\n",
            "Class Prediction Counts:\n",
            "갈취 대화: 92\n",
            "직장 내 괴롭힘 대화: 101\n",
            "일반 대화: 75\n",
            "기타 괴롭힘 대화: 140\n",
            "협박 대화: 92\n",
            "\n",
            "Predictions saved to /content/drive/MyDrive/modu/\bDLTON/test_with_predictions_softvoting_2412092105.csv\n",
            "Submission file saved to /content/drive/MyDrive/modu/\bDLTON/submission_softvoting_2412092105.csv\n"
          ]
        }
      ]
    }
  ]
}